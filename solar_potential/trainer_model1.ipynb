{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80994cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "import torch\n",
    "from detectron2.utils.logger import setup_logger, log_every_n_seconds\n",
    "setup_logger()\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor, HookBase\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils import comm\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "from detectron2.data.datasets.coco import convert_to_coco_json\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.structures import BoxMode\n",
    "import logging\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57179f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat={'rooftops':0} #Order should be same in MetadataCatalog\n",
    "def get_dict(img_dir):\n",
    "    os.chdir(img_dir)\n",
    "    count = 1\n",
    "    file_list=[]\n",
    "    for file in glob.glob(\"*.json\"):\n",
    "        file_list.append(file)\n",
    "    dataset_dicts = []\n",
    "    for file in file_list:\n",
    "        json_file = os.path.join(img_dir, file)\n",
    "        with open(json_file) as f:\n",
    "            imgs = json.load(f)\n",
    "            \n",
    "   \n",
    "        record = {}\n",
    "        filename = os.path.join(img_dir,imgs['imagePath'])\n",
    "        height,width = imgs['imageHeight'],imgs['imageWidth']\n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = count\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        objs = []\n",
    "        for i in range(len(imgs['shapes'])):\n",
    "            tmp = imgs['shapes'][i]['points']\n",
    "            tmp_mat = np.matrix(tmp)\n",
    "            xmin,xmax,ymin,ymax = np.min(tmp_mat[:,0]),np.max(tmp_mat[:,0]),np.min(tmp_mat[:,1]),np.max(tmp_mat[:,1])\n",
    "            poly = list(np.ravel(tmp_mat))\n",
    "            obj = {\n",
    "                        \"bbox\": [xmin, ymin, xmax, ymax],\n",
    "                        \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                        \"segmentation\": [poly],\n",
    "                        \"category_id\": cat[imgs['shapes'][i]['label']],\n",
    "                    }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "        count += 1\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22b3b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = # <directory with a folder named \"train\" containing labelled images>\n",
    "for d in ['train']:\n",
    "    DatasetCatalog.register(\"<datasetname>_train\" ,lambda d=d:get_dict(im_dir+'/' +d))\n",
    "    MetadataCatalog.get('<datasetname>_train').set(thing_classes=['rooftops'])\n",
    "project_metadata = MetadataCatalog.get(\"<datasetname>_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "811fa663",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")) # Pre-Trained model architecture\n",
    "cfg.DATASETS.TRAIN = (\"<datasetname>_train\",) # Custom Dataset\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 8 #Define number of workers according to the machine\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\") #Pre-Trained model weights\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1 # Number of images per batch\n",
    "cfg.SOLVER.BASE_LR = 0.0025 #Base learning rate {Tweak as per dataser size and epochs}\n",
    "cfg.SOLVER.MAX_ITER =50000 #Maximum Epochs\n",
    "cfg.SOLVER.STEPS = (5000,12000,20000,35000) #Decreasing the learning rate after given epochs\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 # Define number of classes in the dataset\n",
    "cfg.OUTPUT_DIR = os.path.join(\"<'path in which output weights will be saved'>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26b4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run as it is\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False) # resume True if using trained weights\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ec82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
