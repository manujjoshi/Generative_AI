{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334c453f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "import torch\n",
    "from detectron2.utils.logger import setup_logger, log_every_n_seconds\n",
    "setup_logger()\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor, HookBase\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils import comm\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "from detectron2.data.datasets.coco import convert_to_coco_json\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.structures import BoxMode\n",
    "import logging\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc630d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat={'concrete':0,'not_concrete':1,'vegetation':2} #Order should be same in MetadataCatalog\n",
    "def get_dict(img_dir):\n",
    "    os.chdir(img_dir)\n",
    "    count = 1\n",
    "    file_list=[]\n",
    "    for file in glob.glob(\"*.json\"):\n",
    "        file_list.append(file)\n",
    "    dataset_dicts = []\n",
    "    for file in file_list:\n",
    "        json_file = os.path.join(img_dir, file)\n",
    "        with open(json_file) as f:\n",
    "            imgs = json.load(f)\n",
    "            \n",
    "   \n",
    "        record = {}\n",
    "        filename = os.path.join(img_dir,imgs['imagePath'])\n",
    "        height,width = imgs['imageHeight'],imgs['imageWidth']\n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = count\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        objs = []\n",
    "        for i in range(len(imgs['shapes'])):\n",
    "            tmp = imgs['shapes'][i]['points']\n",
    "            tmp_mat = np.matrix(tmp)\n",
    "            xmin,xmax,ymin,ymax = np.min(tmp_mat[:,0]),np.max(tmp_mat[:,0]),np.min(tmp_mat[:,1]),np.max(tmp_mat[:,1])\n",
    "            poly = list(np.ravel(tmp_mat))\n",
    "            obj = {\n",
    "                        \"bbox\": [xmin, ymin, xmax, ymax],\n",
    "                        \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                        \"segmentation\": [poly],\n",
    "                        \"category_id\": cat[imgs['shapes'][i]['label']],\n",
    "                    }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "        count += 1\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f343f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = # <directory with a folder named \"train\" containing labelled images>\n",
    "for d in ['train']:\n",
    "    DatasetCatalog.register(\"<datasetname>_train\" ,lambda d=d:get_dict(im_dir+'/' +d))\n",
    "    MetadataCatalog.get(\"<datasetname>_train\").set(thing_classes=['concrete','not_concrete','vegetation'])\n",
    "project_metadata = MetadataCatalog.get(\"<datasetname>_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f797176",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")) # Pre-Trained model architecture\n",
    "cfg.DATASETS.TRAIN = (\"<datasetname>_train\",) # Custom Dataset\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 8 #Define number of workers according to the machine\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\") #Pre-Trained model weights\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1 # Number of images per batch\n",
    "cfg.SOLVER.BASE_LR = 0.005 #Base learning rate {Tweak as per dataser size and epochs}\n",
    "cfg.SOLVER.MAX_ITER =60000 #Maximum Epochs\n",
    "cfg.SOLVER.STEPS = (24000,36000,50000) #Decreasing the learning rate after given epochs\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 # Define number of classes in the dataset\n",
    "cfg.OUTPUT_DIR = os.path.join(\"<'path in which output weights will be saved'>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55218a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run as it is\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False) # resume True if using trained weights\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
