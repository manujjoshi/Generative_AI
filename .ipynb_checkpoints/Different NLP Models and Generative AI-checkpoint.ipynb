{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf913fd",
   "metadata": {},
   "source": [
    "### [Colah blog on LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "## RNN\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)\n",
    "## Long short-term memory (LSTM)\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n",
    "## Gated recurrent units (GRUs)\n",
    "### [Video Link](https://www.youtube.com/watch?v=tOuXgORsXJ4)\n",
    "![](https://149695847.v2.pressablecdn.com/wp-content/uploads/2021/08/GRU.png)\n",
    "### Comparision: From working of both layers i.e., LSTM and GRU, GRU uses less training parameter and therefore uses less memory and executes faster than LSTM whereas LSTM is more accurate on a larger dataset. One can choose LSTM if you are dealing with large sequences and accuracy is concerned, GRU is used when you have less memory consumption and want faster results. \n",
    "### [LSTM vs GRU (Awesome blog)](https://analyticsindiamag.com/lstm-vs-gru-in-recurrent-neural-network-a-comparative-study/)\n",
    "## Bidirectional RNN\n",
    "![](https://miro.medium.com/v2/resize:fit:764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)\n",
    "### drawback: Slow as compared to RNN and LSTM RNN\n",
    "## Seq to seq models\n",
    "![](https://qph.cf2.quoracdn.net/main-qimg-212dcf844b853da3d1f7644f69c14721-pjlq)\n",
    "### Disadvantage: As the sentence length increases respect to encoders and decoders the accuracy decreases\n",
    "![](https://teksands.ai/resources/images/blogs/attention-mechanism/xattention-mechanism-1.jpg.pagespeed.ic.z4hj0r5YDY.jpg)\n",
    "### rescue: Attention models which uses bi-directional LSTM\n",
    "## Attention Mechanism\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2019/11/Screenshot-2019-11-19-at-2.16.39-PM.png)\n",
    "**Research Paper:** [Link](https://arxiv.org/pdf/1409.0473.pdf)\n",
    "## Transformers\n",
    "![](https://jalammar.github.io/images/t/the_transformer_3.png)\n",
    "![](https://jalammar.github.io/images/t/Transformer_decoder.png)\n",
    "![](https://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png)\\\n",
    "![](https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png)\n",
    "### [Jalammar blog on transformers](https://jalammar.github.io/illustrated-transformer/)\n",
    "### [research Paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n",
    "![](https://heidloff.net/assets/img/2023/02/transformers.png)\n",
    "### [My Transforemer and BERt Notes](https://github.com/manujjoshi/Transformers_notes)\n",
    "## How Chat GPT is trained??\n",
    "[Blog Link](https://rpradeepmenon.medium.com/discover-how-chatgpt-is-trained-1f20b9777d1b)\n",
    "![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*DalLp5-RUCEIPdwwiVrZJA.jpeg)\n",
    "## Important Topics to Consider\n",
    "### [Cosine Similarity (Awesome video)](https://www.youtube.com/watch?v=ieMjGVYw9ag)\n",
    "\n",
    "# Generative AI Topics =================\n",
    "- [Interesting new models and Technologies](https://www.youtube.com/watch?v=qVSBPm-CSL8&list=PLaFUiA52BD9H-EZJfgR9qEBVNdiXJuucC&index=1)\n",
    "#### OpenAi \n",
    "\n",
    "1) **What is embedding** \n",
    "    - [OpenAI Embeddings and Vector Databases](https://www.youtube.com/watch?v=ySus5ZS0b94)\n",
    "2) **What is a LLM ( Large Language Model )** \n",
    "    - [Jay Alammar...What is LLM??](https://youtu.be/BBQLPu9XqTk)\n",
    "3) **Prompt Engineering**\n",
    "    - [Prompt Engineering with LangChain](https://youtu.be/t2bSApmPzU4) \n",
    "    - **[Advanced Prompting Techniques](https://machinelearningmastery.com/prompt-engineering-for-effective-interaction-with-chatgpt/)** positive, negative, zero shot, one shot, few shot, chain of thoughts, self criticism, iterative and more\n",
    "4) **Negative Prompt**: Negative prompts are directions for information that should not be provided in response.\n",
    "5) **Open Ai Models**\n",
    "6) **Text- Davenchi-003 Model** \n",
    "7) **Curie Model**\n",
    "8) **Babbage Model** \n",
    "9) **Gpt 3.5 Model** \n",
    "10) **Whisper Model** \n",
    "11) **All Gpt 5 Models** \n",
    "    - [How GPT 3 Works by Jay Alammar](https://www.youtube.com/watch?v=MQnJZuBGmSQ)\n",
    "12) **Difference between All models** \n",
    "13) **Dalle Model for image generation** \n",
    "14) **Text-embedding-ada-002 Model** \n",
    "15) **Reverse Prompt** \n",
    "16) **Prompt Bracking**\n",
    "17) **Pricing of OpenAi** \n",
    "18) **Langchain**\n",
    "    - [LangChain Explained](https://www.youtube.com/watch?v=aywZrzNaKjs)\n",
    "    - [What is LangChain by Krish](https://www.youtube.com/watch?v=_FpT1cwcSLg&list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar)\n",
    "    - [Langchain Nicola: Build a auto GPT app](https://youtu.be/MlK6SIjcjE8)\n",
    "    - [Langchain Complete Course](https://www.youtube.com/watch?v=_v_fgW2SkkQ&list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5)\n",
    "19) **Pandas Ai** \n",
    "20) **Lamma Index with vector databases** [Link](https://youtu.be/WKvAWub8VCU) llama index previously known GPT-Index is used for semantic search [Sample_Notebook_Link](https://github.com/pinecone-io/examples/blob/master/learn/generation/llama-index/llama-index-intro.ipynb)\n",
    "21) **Chat Bot with Open ai**\n",
    "22) **Redis Vector Database** [Link](https://www.youtube.com/watch?v=OqCK95AS-YE) Redis, which stands for Remote Dictionary Server, is an open-source in-memory data structure store. It is often referred to as a data structure server because it allows you to store and manipulate various types of data structures, such as strings, hashes, lists, sets, sorted sets, and more. Redis is known for its high-performance and low-latency characteristics, making it a popular choice for caching, real-time analytics, session management, and various other use cases.<br>\n",
    "**Key Features:**\n",
    "    - In-Memory Storage\n",
    "    - Store various Data Structures\n",
    "    - Persistence: This can be achieved through snapshotting or by using an append-only file (AOF) that logs all write operations. This ensures that data can be recovered even after a restart.\n",
    "    - Caching\n",
    "    - Atomic Operations\n",
    "23) **Azure Open Ai** \n",
    "24) **Memory for chatbot** \n",
    "25) **Tokens in OpenAi**\n",
    "26) **GPT 4**\n",
    "27) **Image Generation**\n",
    "    - [Stable Diffusion AI has Taken the World By Storm](https://www.analyticsvidhya.com/blog/2022/09/stable-diffusion-ai-has-taken-the-world-by-storm/)\n",
    "    - [Lexica: Image generation Platform](https://lexica.art/)\n",
    "    - **[DALLE 2 Beautiful Blog](https://medium.com/augmented-startups/how-does-dall-e-2-work-e6d492a2667f)**\n",
    "    ![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*w2W7tw7LtDOvToKNPE34lw.png)<br>\n",
    "    - **[DALLE_2 vs Stable Diffusion vs MidJourney](https://www.marktechpost.com/2022/11/14/how-do-dall%C2%B7e-2-stable-diffusion-and-midjourney-work/)**<br><br>\n",
    "28) **[Chat GPT vs BARD](https://www.youtube.com/watch?v=Ae6q7v7pOxM&list=PLZoTAELRMXVPvMxEAuGNQKs-HeIKYzjWm)**\n",
    "29) **[How Chat GPT is trained??](https://www.youtube.com/watch?v=rcxXiLhxhsk&list=PLZoTAELRMXVPvMxEAuGNQKs-HeIKYzjWm&index=2&pp=iAQB)**\n",
    "30) **[Chainlit: make your LLM apps in minutes](https://youtu.be/tv7rn5AsxFY)**\n",
    "31) **LoRA**\n",
    "32) **LLama Meta**\n",
    "33) **How to create a chatbot with OpenAI ChatGPT:** [Link](https://www.youtube.com/watch?v=XzEilWbMAs8)\n",
    "34) **What are VECTOR Databases, Why is the hype:** [Link](https://youtu.be/dN0lsF2cvm4)\n",
    "35) **[GPT Explained: GPT => GPT2 => GPT3 => Chat GPT](https://www.youtube.com/watch?v=3IweGfgytgY)**\n",
    "36) **[Chat GPT Explained](https://www.youtube.com/watch?v=NpmnWgQgcsA)**\n",
    "37) **[BERT Explained](https://www.youtube.com/watch?v=xI0HHN5XKDo)**\n",
    "    - BERT Give Contextualized Embeddings\n",
    "    - [Allamar Blog](https://jalammar.github.io/illustrated-bert/)\n",
    "38) **Google T5 (Text to Text Transfer Transformer Model) and Flan-T5 LLM** [Link](https://youtu.be/SHMsdAPo2Ls)\n",
    "39) **LLama-2** [Link](https://www.youtube.com/watch?v=yZ9jkgN2xHQ)\n",
    "40) **Jukebox: A Generative model for music** [Link](https://github.com/openai/jukebox)\n",
    "41) **OPEN AI Clip Explained(multi-model ML)** [Link](https://www.youtube.com/watch?v=fGwH2YoQkDM)\n",
    "42) **7 Open-source OPEN AI models** [Link](https://analyticsindiamag.com/7-open-source-models-from-openai/) [Evals](https://analyticsindiamag.com/after-whisper-openai-quietly-launches-evals/) [Whisper](https://analyticsindiamag.com/openai-open-sources-whisper-a-multilingual-speech-recognition-system/) [Dall-E2](https://analyticsindiamag.com/whats-the-big-deal-about-dall-e-2/) Spinning-up CLIP Jukebox Point-E\n",
    "43) **OPEN AI Products APIs [Link](https://openai.com/product)**\n",
    "44) **Azure Open AI** [Link](https://www.youtube.com/watch?v=JXvSbu12VY4&list=PLiQS6N-W1p3lZUqyx0KQuGhhVYWH6wgDw)\n",
    "45) **Azure OpenAI Embeddings QnA** [Link](https://github.com/ruoccofabrizio/azure-open-ai-embeddings-qna)\n",
    "46) **ChatGPT + Enterprise data with Azure OpenAI and Cognitive Search** [Link](https://github.com/Azure-Samples/azure-search-openai-demo)\n",
    "47) **Chat with your SQL Data using Chat GPT** [Link](https://www.youtube.com/watch?v=1FeBkAccobY&list=PLiQS6N-W1p3lZUqyx0KQuGhhVYWH6wgDw&index=5)\n",
    "48) **Build an E-commerce Chatbot With Redis, LangChain, and OpenAI** [Link](https://redis.com/blog/build-ecommerce-chatbot-with-redis/)\n",
    "49) **Falcon AI: The New Open Source Large Language Model** [Link](https://www.analyticsvidhya.com/blog/2023/07/falcon-ai-the-new-open-source-large-language-model/) && **[Falcon_chat_space](https://huggingface.co/spaces/HuggingFaceH4/falcon-chat)**\n",
    "# Other Important Topics\n",
    "#### Google Lambda\n",
    "#### [Cohere.ai Notebooks on LLMs](https://github.com/cohere-ai/notebooks)\n",
    "#### Generated Pre-training Transformers(GPT)\n",
    "#### Reinforecement Learning from Human Feedback(RLHF)\n",
    "#### Drug Discovery\n",
    "## [What are Autoencoders and what are they used for?](https://www.youtube.com/watch?v=2_h61v6mgRc)\n",
    "![](https://miro.medium.com/v2/resize:fit:600/1*nqzWupxC60iAH2dYrFT78Q.png)\n",
    "## [What are variational Autoencoders??](https://youtu.be/YV9D3TWY5Zo)\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/VAE_Basic.png/425px-VAE_Basic.png)\n",
    "## [How does word2vec work with CBOW](https://www.youtube.com/watch?v=Q95SIG4g7SA&list=PLZoTAELRMXVMdJ5sqbCK2LiM0HhQVWNzm&index=30)\n",
    "![](https://mohitmayank.com/a_lazy_data_science_guide/imgs/w2v_skipgram.png)\n",
    "## [How does Avgword2vec  work?? why it's needed?? For classification purpose](https://www.youtube.com/watch?v=cyvkMFZnheo&list=PLZoTAELRMXVMdJ5sqbCK2LiM0HhQVWNzm&index=31)\n",
    "## How to Train Chat GPT\n",
    "![](https://pbs.twimg.com/media/FpuGhItWcAEsXBm.jpg:large)\n",
    "## Transfer Learning vs Meta Learning\n",
    "### Transfer Learning\n",
    "![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*5zTB3ysRwYUBF34UknatHw.jpeg)\n",
    "### Meta Learning\n",
    "![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*zQMO5-TgyQTRLrad_t0OGQ.jpeg)\n",
    "### Azure OpenAI Embeddings QnA\n",
    "![](https://github.com/ruoccofabrizio/azure-open-ai-embeddings-qna/raw/main/docs/architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4871543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
